import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
import logging

from configs.config import settings
from utils.utils import (
    generate_lightfm_recs_mapper,
    load_model,
    read_parquet
)


def prepare_data_for_train():
    """
    function to prepare data to train catboost classifier.
    Basically, you have to wrap up code from full_recsys_pipeline.ipynb
    where we prepare data for classifier. In the end, it should work such
    that we trigger and use fit() method from ranker.py

        paths_config: dict, where key is path name and value is the path to data
    """
    # load model artefacts
    model = load_model(
        file_name=settings.LFM_TRAIN_PARAMS.MODEL_PATH)
    dataset = load_model(
        file_name=settings.LFM_TRAIN_PARAMS.MAPPER_PATH)

    local_test = read_parquet(
        file_folder=settings.DATA_FOLDERS.SPLITTED_DATA_FOLDER,
        file_name=settings.DATA_SPLIT_P.INTERACTIONS_LOCAL_TEST)

    # pred candidates
    test_preds = pd.DataFrame({
        "user_id": local_test[settings.FEATURES.USER_IDS].unique()})

    # init mapper with model
    item_ids = list(dataset.mapping()[2].values())
    item_inv_mapper = {v: k for k, v in dataset.mapping()[2].items()}
    mapper = generate_lightfm_recs_mapper(
        model,
        item_ids=item_ids,
        known_items=dict(),
        N=settings.LFM_PREDS_PARAMS.TOP_K,
        user_features=None,
        item_features=None,
        user_mapping=dataset.mapping()[0],
        item_inv_mapping=item_inv_mapper,
        num_threads=20,
    )
    test_preds['item_id'] = test_preds['user_id'].map(mapper)

    # define target & prepare ranker sample
    test_preds = test_preds.explode('item_id')

    logging.info(f"Shape of the predictions: {test_preds.shape}")

    test_preds['rank'] = test_preds.groupby('user_id').cumcount() + 1
    logging.info(
        f"Number of unique candidates generated by the LFM: {test_preds.item_id.nunique()}"
    )

    train_data = get_ranker_sample(test_preds)

    return train_data

def get_ranker_sample(test_preds: pd.DataFrame):
    """
    final step to use candidates generation and users interaction to define
    train data - join features, define target, split into train & test samples
    """
    local_test = read_parquet(
        file_folder=settings.DATA_FOLDERS.SPLITTED_DATA_FOLDER,
        file_name=settings.DATA_SPLIT_P.INTERACTIONS_LOCAL_TEST
    )

    # prepare train & test
    positive_preds = pd.merge(test_preds, local_test, how='inner', on=['user_id', 'item_id'])
    positive_preds['target'] = 1
    logging.info(f"Shape of the positive target preds: {positive_preds.shape}")

    negative_preds = pd.merge(local_test, test_preds, how='left', on=['user_id', 'item_id'])
    negative_preds = negative_preds.loc[negative_preds['event_type'] != 'purchase'].sample(frac=.05)
    negative_preds['target'] = 0
    logging.info(f"Shape of the negative target preds: {positive_preds.shape}")

    # random split to train ranker
    train_users, test_users = train_test_split(
        local_test['user_id'].unique(),
        test_size=settings.RANKER_DATA.TEST_SIZE,
        random_state=settings.RANKER_DATA.RANDOM_STATE
    )

    cbm_train_set = shuffle(
        pd.concat(
            [positive_preds.loc[positive_preds['user_id'].isin(train_users)],
             negative_preds.loc[negative_preds['user_id'].isin(train_users)]]
        )
    )

    cbm_test_set = shuffle(
        pd.concat(
            [
                positive_preds.loc[positive_preds["user_id"].isin(test_users)],
                negative_preds.loc[negative_preds["user_id"].isin(test_users)],
            ]
        )
    )

    # users_data = read_parquet_from_gdrive(settings.RANKER_DATA.USERS_DATA_PATH)
    # items_data = read_parquet_from_gdrive(settings.RANKER_DATA.MOVIES_DATA_PATH)

    # join user features
    # cbm_train_set = pd.merge(
    #     cbm_train_set,
    #     users_data[["user_id"] + settings.USER_FEATURES],
    #     how="left",
    #     on=["user_id"],
    # )
    # cbm_test_set = pd.merge(
    #     cbm_test_set,
    #     users_data[["user_id"] + settings.USER_FEATURES],
    #     how="left",
    #     on=["user_id"],
    # )
    # # join item features
    # cbm_train_set = pd.merge(
    #     cbm_train_set,
    #     items_data[["item_id"] + settings.ITEM_FEATURES],
    #     how="left",
    #     on=["item_id"],
    # )
    # cbm_test_set = pd.merge(
    #     cbm_test_set,
    #     items_data[["item_id"] + settings.ITEM_FEATURES],
    #     how="left",
    #     on=["item_id"],
    # )

    # final steps
    # ID_COLS = ['user_id', 'item_id']
    # TARGET = ['target']
    # CATEGORICAL_COLS = ['platform', 'event_type']
    # DROP_COLS = ['utc_event_time', 'utc_event_date', 'id', 'year', 'month', 'day',
    #              'timestamp_event_time', 'lag_event_timestamp', 'is_first_event', 'timestamp_first_event', 'session_id',
    #              'session_duration']

    drop_cols = (
        settings.RANKER_PREPROCESS_FEATURES.ID_COLS.to_list()
        + settings.RANKER_PREPROCESS_FEATURES.DROP_COLS.to_list()
        + settings.RANKER_PREPROCESS_FEATURES.TARGET.to_list()
    )
    X_train, y_train = (
        cbm_train_set.drop(
            drop_cols,
            axis=1,
        ),
        cbm_train_set[settings.FEATURES.TARGET],
    )

    X_test, y_test = (
        cbm_test_set.drop(
            drop_cols,
            axis=1,
        ),
        cbm_test_set[settings.FEATURES.TARGET],
    )
    logging.info(f"X_train.shape, X_test.shape {X_train.shape, X_test.shape}")

    # no time dependent feature - we can leave it with mode
    X_train = X_train.fillna(X_train.mode().iloc[0])
    X_test = X_test.fillna(X_test.mode().iloc[0])

    return X_train, X_test, y_train, y_test


# test_preds = prepare_data_for_train()
# print(test_preds.head(5))
# X_train, X_test, y_train, y_test = get_ranker_sample(test_preds)
# print(X_train.head())


def prepare_ranker_input(
    candidates: dict[int, int],
    item_features: dict[int, any],
    user_features: dict[int, any],
    ranker_features_order,
):
    ranker_input = []
    for k in item_features.keys():
        item_features[k].update(user_features)
        item_features[k]["rank"] = candidates[k]
        item_features[k] = {
            feature: item_features[k][feature] for feature in ranker_features_order
        }
        ranker_input.append(list(item_features[k].values()))

    return ranker_input

